{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powerful Classifiers \n",
    "Here we will try powerful classifiers, including support vector machines, random forests, neural networks. Remember that 90% of Machine Learning is about classification. This lecture includes precise but uninterpretable classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file\n",
    "Commonly two libraries are used to load a csv files.\n",
    "- numpy function `np.loadtext` and `np.genfromtext ` \n",
    "- pandas function `pd.read_csv`\n",
    "\n",
    "Here we prefer using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "path='data/'\n",
    "filename = path+'spamdata.csv'\n",
    "spam = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam.values[:,:57]\n",
    "y = spam.values[:,57]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \\\n",
    "                                    test_size = 0.2, random_state=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "Random forests is one of the powerful classification tools. Computations for moderate number of samples is rather fast. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classification_tree_spam = DecisionTreeClassifier(max_depth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698369565217392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag = BaggingClassifier(classification_tree_spam, n_estimators=100, \\\n",
    "                        random_state=1)\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "y_bag_train = bag.predict(X_train)\n",
    "accuracy_score(y_train, y_bag_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446254071661238"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bag_test = bag.predict(X_test)\n",
    "accuracy_score(y_test, y_bag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967391304347826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, \\\n",
    "                            random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_train = rf.predict(X_train)\n",
    "accuracy_score(y_train, y_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500542888165038"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rf_test = rf.predict(X_test)\n",
    "accuracy_score(y_test, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the depth of the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accuracy_score vector\n",
    "acc = []\n",
    "acc_train = []\n",
    "depth = np.arange(1, 50)\n",
    "# Calculate accuracy score on the test set for different depths of the trees\n",
    "for i in depth:\n",
    "    # Fit the Regression Tree\n",
    "    dt = RandomForestClassifier(n_estimators=100, max_depth=i, random_state=1)\n",
    "    dt.fit(X_train,y_train)\n",
    "    # Predict on the test set\n",
    "    y_pred = dt.predict(X_test)\n",
    "    # Compute the accuracy\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    acc.append(score)\n",
    "    acc_train.append(accuracy_score(y_train, dt.predict(X_train)))\n",
    "# Plot results    \n",
    "plt.plot(depth, acc, '-', depth, acc_train, 'r')\n",
    "plt.xlabel('Depth of the trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('spam');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best depth of the trees is \", np.argmax(acc)+1, \" with accuracy of \", np.amax(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppor Vector Machines\n",
    "\n",
    "SVMs are like linear regression, expanded in kernel space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try C=1, C=10, C=100\n",
    "from sklearn.svm import SVC\n",
    "sv = SVC(C=10)\n",
    "sv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svc_train = sv.predict(X_train)\n",
    "accuracy_score(y_svc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svc_test = sv.predict(X_test)\n",
    "accuracy_score(y_svc_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one iteration of KFold for single C\n",
    "from sklearn.model_selection import KFold\n",
    "k = 5\n",
    "acck = np.zeros(k)\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "i = 0\n",
    "for train_i, test_i in kf.split(spam):\n",
    "    sv = SVC(C=10)\n",
    "    sv = sv.fit(X[train_i], y[train_i])\n",
    "    acck[i]=accuracy_score(sv.predict(X[test_i]), y[test_i], normalize=False)\n",
    "    i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(acck)/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One iteration of Kfold and tune C between zero and 10\n",
    "nb = 5\n",
    "penalty = np.linspace(0.01, 100, nb)\n",
    "k = 5\n",
    "acck = np.zeros(k)\n",
    "acc = np.zeros(len(penalty))\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "for c in range(len(penalty)):\n",
    "    i = 0\n",
    "    for train_i, test_i in kf.split(spam):\n",
    "        sv = SVC(C=penalty[c])\n",
    "        sv = sv.fit(X[train_i], y[train_i])\n",
    "        acck[i]=accuracy_score(sv.predict(X[test_i]), y[test_i], normalize=False)\n",
    "        i+=1\n",
    "    acc[c] = np.sum(acck)/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define a function to draw a nice plot of an SVM\n",
    "def plot_svc(svc, X, y, h=0.02, pad=0.25):\n",
    "    x_min, x_max = X[:, 0].min()-pad, X[:, 0].max()+pad\n",
    "    y_min, y_max = X[:, 1].min()-pad, X[:, 1].max()+pad\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.2)\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], s=70, c=y, cmap=mpl.cm.Paired)\n",
    "    # Uncomment the next two lines if you want support vectors indicated in plot by vertical lines\n",
    "    #sv = svc.support_vectors_\n",
    "    #plt.scatter(sv[:,0], sv[:,1], c='k', marker='x', s=100, linewidths='1')\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()\n",
    "    #print('Number of support vectors: ', svc.support_.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random data: 30 observations of 2 features and divide into two classes.\n",
    "np.random.seed(5)\n",
    "X = np.random.randn(30,2)\n",
    "y = np.repeat([1,-1], 15)\n",
    "\n",
    "X[y == -1] = X[y == -1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the data to see whether the classes are linearly separable:\n",
    "plt.scatter(X[:,0], X[:,1], s=70, c=y, cmap=mpl.cm.Paired)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we fit the support vector classifier:\n",
    "svc = SVC(C=10, kernel='rbf')\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the support vector classifier by calling the  𝚙𝚕𝚘𝚝_𝚜𝚟𝚌()  function on the output of the call to  𝚂𝚅𝙲() , as well as the data used in the call to  𝚂𝚅𝙲() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svc, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = SVC(C=1, kernel='linear')\n",
    "svc2.fit(X, y)\n",
    "plot_svc(svc2, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the optimal C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Select the optimal C parameter by cross-validation\n",
    "tuned_parameters = [{'C': [0.001, 0.01, 0.1, 1, 5, 10, 100]}]\n",
    "clf = GridSearchCV(SVC(kernel='linear'), tuned_parameters, cv=10, scoring='accuracy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "Shallow neural networks often produces comparable results with random forest, bagging and boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build two hidden layers, each layer with 10 neurons\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(10, 10), activation='logistic')\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(nn.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(nn.predict(X_test), y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
